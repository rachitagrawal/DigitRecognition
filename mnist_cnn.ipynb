{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "## Project: Digit Recognition using Convolution Neural Network \n",
    "\n",
    "In this project, I have picked up a problem that might be common in the field of Machine Learning but the approach I am taking is not very common. I am taking the problem of building a MNIST Classifier using Convolution Neural Network using neural network framework with the following motivation:\n",
    "\n",
    "1. Learn the nuances of Convolution Neural Network.\n",
    "2. Compare different neural network framework for quick development. \n",
    "3. Learn this framework.\n",
    "4. Solve a problem in Computer Vision domain using the above framework.\n",
    "\n",
    "I have an ultimate goal to build my own prototype of self-driving car and I belive the above goals lay down a good foundation for this ultimate goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Getting Started\n",
    "In this project, I am trying to solve the problem of digit recognition on MNIST dataset using Convolution Neural Network Model. First I am going through the details of the Input Data used, Network Architecture, followed with the comparison of different NN framework and then followed with the result of the above model on a chosen framework. \n",
    "\n",
    "### Data Set\n",
    "The MNIST dataset comprises of 60000 training examples and 10000 test examples of the handwritten digits 0-9, formatted as 28x28-pixel monochrome images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Understanding the Network Architecture\n",
    "The below model is used to classify the images in MNIST dataset:\n",
    "\n",
    "* **Convolution Layer #1**: 32 filters of kernel size 5x5 with ReLU activation function is applied. \n",
    "* **Pooling Layer #1**: Using max pooling with 2x2 filter and stride of 2.\n",
    "* **Convolution Layer #2**: Increase the features that can be extracted by applying 64 5x5 filters, with ReLU activation function.\n",
    "* **Pooling Layer #2**: Using max pooling with 2x2 filter with a stride of 2.\n",
    "* **Fully Connected Layer #1**: A Fully Connected layer with 1024 nodes/neurons with ReLU activation function.\n",
    "* **Logits Layer #1:** A logit layer with 10 nodes/nerons that returns the values for the predictions. These values are in the range of [-inf, +inf].\n",
    "\n",
    "Using the above architecture, we will build each of these layers step-by-step hereon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Implementing the Network\n",
    "\n",
    "### Input Layer\n",
    "\n",
    "Input is a gray-scale image from MNIST dataset with a dimension of 28x28. But convolution & pooling layers in tensorlow(TF) expects the input size in format [batch_size, Height, Width, NumChannels]. So, to suit this input requirement out input image can be seen as 28(H)x28(W)x1(D). We use 'reshape' function to achieve this transformation. \n",
    "\n",
    "* Input: [batch_size, 28, 28]\n",
    "* Output: [batch_size, 28, 28, 1]\n",
    "\n",
    "### Convolution Layer 1\n",
    "\n",
    "In the convolution layer, we try to extract 'K' features by applying 'K' filters from a sub-region of  'M' x 'N'. There is no theoretical approach to get the right values for these hyper-parameters. It is emperically calculated. For our experiments, we pick the most common choice for these parameters. We pick 32 filters of 5x5 kernel size with padding of value=0.\n",
    "\n",
    "* Input: [batch_size, 28, 28, 1]\n",
    "* Output: [batch_size, 28, 28, 32]\n",
    "\n",
    "### Pooling Layer 1\n",
    "\n",
    "Every convolution layer is typically followed with a pooling layer to down-sample the feature volume. Again in the absence of any emperical data, we pick the most common choice of pooling layer i.e. 2x2 with a step size of 2. We use max-pooling function and due to the kernel-size of 2x2, it reduces the input dimension to H/2 x W/2. \n",
    "\n",
    "* Input: [batch_size, 28, 28, 32]\n",
    "* Output: [batch_size, 14, 14, 32]\n",
    "\n",
    "### Convolution Layer 2\n",
    "\n",
    "Multiple architectures like AlexNet, GoogleNet, MobilNet etc. suggests that a convolution layer following a pooling should increase the number of features in the same order as the previous pooling layer has reduced the dimension by. Keeping this in mind, we use 64 filters now with our default kernel size of 5x5. \n",
    "\n",
    "* Input: [batch_size, 14, 14, 32]\n",
    "* Output: [batch_size, 14, 14, 64]\n",
    "\n",
    "### Pooling Layer 2\n",
    "\n",
    "As Pooling Layer 1, we use another max-pooling function to down-sampler the feature volume. \n",
    "\n",
    "* Input: [batch_size, 14, 14, 64]\n",
    "* Output: [batch_size, 7, 7, 64]\n",
    "\n",
    "### Fully Connected Layer 1\n",
    "\n",
    "Next, we add a fully connected layer to do classification based on the features extracted by the multiple convolution and pooling layer. Any fully connected layer expects input in 2-dimension so we transform our output of pooling layer 2 into a 2-dimension feature volume. Post this, we pass it through the fully connected layer of 1024 neurons. \n",
    "\n",
    "* Input: [batch_size, 7, 7, 64]\n",
    "* Output: [batch_size, 1024]\n",
    "\n",
    "### Fully Connected Layer 2\n",
    "\n",
    "We add another fully connected layer to get the final classification. Since our output label size is 10, we take 10 neurons in this layer. At the end of this layer we will have 10 output values ranging from [-inf, inf], hence we apply softmax function to convert this space into this range [0, 1]. Also, softmax function converts score for reach class into probability such a way that sum of these scores is always 1. \n",
    "\n",
    "* Input: [batch_size, 1024]\n",
    "* Output: [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Framework\n",
    "\n",
    "We combine all the layers discussed above to come up with the final CNN using tensorflow in python. We had multiple options to choose from among the various Neural Network framework available. I did my literature survey to compare these different framework and came up with the following summary:\n",
    "\n",
    "--------------------------------------------------------\n",
    "|Property | Caffe | Neon | TensorFlow | Theano | Torch |\n",
    "|------------------------------------------------------|\n",
    "| Core | C++ | Python | C++ | Python | Lua|    \n",
    "| CPU | Yes | Yes | Yes | Yes | Yes | \n",
    "| Multi-threaded CPU | Blas | Only Data Loader | Eigen | Blas, conv2D, limited OpenMP | Widely Used|    \n",
    "| GPU | Yes | Customized nVidia backend | Yes | Yes | Yes|    \n",
    "|Multi-GPU | Only Data Parallel | Yes | Most Flexible | No | Yes |    \n",
    "| Nvidia cuDNN | Yes | No | Yes | Yes | Yes|    \n",
    "| Quick Deploy, on standard Models | Easiest | Yes | Yes | No | Yes |   \n",
    " | Auto Gradient Compu | Yes | Yes | Yes | Most flexible | Yes |    \n",
    "    \n",
    "\n",
    "Looking at the above comparison metric, *Torch* and *TensorFlow* are the top two choice. But TensorFlow has a better support for Multi-GPU. This is a very important metric becuase, GPUs are heavily used for the training and having better support for multi-GPU means huge time savings. Due to this, I choose TensorFlow as the framework to learn and use for my project. \n",
    "\n",
    "## Tying up all the Layers\n",
    "\n",
    "### Convolution Neural Network\n",
    "\n",
    "Combining all the layers expalined above in tensorflow we create a CNN model as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a CNN with the above architecture\n",
    "# features --> Input Features\n",
    "# labels --> Output labels\n",
    "# mode --> Mode to specify if it's training or testing run\n",
    "def digit_classifier(features, labels, mode):\n",
    "    #Input Layer - \n",
    "    inputLayer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    \n",
    "    #Convolution Layer 1\n",
    "    #InputSize: [batch_size, 28, 28, 1]; \n",
    "    #OutputSize: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "                inputs=inputLayer,\n",
    "                filters=32,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "    \n",
    "    #Pooling Layer 1\n",
    "    #InputSize: [batch_size, 28, 28, 32]\n",
    "    #OutputSize: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.pooling2d(\n",
    "                inputs=conv1,\n",
    "                pool_size=[2, 2],\n",
    "                strides=2)\n",
    "    \n",
    "    #Convolution Layer 2\n",
    "    #InputSize: [batch_size, 14, 14, 32]\n",
    "    #OutputSize: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "                inputs=pool1,\n",
    "                filters=64,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "    \n",
    "    #Pooling Layer 2\n",
    "    #Input Size: [batch_size, 14, 14, 64]\n",
    "    #Output Size: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.pooling2d(\n",
    "                inputs=conv2,\n",
    "                pool_size=[2,2],\n",
    "                strides=2)\n",
    "    \n",
    "    #Preparation layer for Fully Connected Layer\n",
    "    #Input Size: [batch_size, 7, 7, 64]\n",
    "    #Output Size: [batch_size, 7*7*64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    \n",
    "    #Fully Connected Layer 1\n",
    "    #Input Size: [batch_size, 3136]\n",
    "    #Output Size: [batch_size, 1024]\n",
    "    fc1 = tf.layers.dense(\n",
    "                inputs=pool2_flat,\n",
    "                units=1024,\n",
    "                activation=tf.nn.relu)\n",
    "    \n",
    "    #Regularization to avoid over-fitting\n",
    "    #Input Size: [batch_size, 1024]\n",
    "    #Output Size: [batch_size, 1024]\n",
    "    dropout = tf.layers.dropout(\n",
    "                inputs=fc1,\n",
    "                rate=0.4,  #Drop Out Rate\n",
    "                training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #Fully Connected Layer 2\n",
    "    fc2 = tf.layers.dense(\n",
    "                inputs=droput,\n",
    "                units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        #Generate predictions for PREDICT and EVAL mode\n",
    "        \"classes\": tf.argmax(input=fc2, axis=1),\n",
    "        \n",
    "        #Generate probabilities\n",
    "        \"probabilities\": tf.nn.softmax(fc2, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    #Calculate loss for both TRAIN and EVAL modes\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=onehot_labels,\n",
    "            logits=fc2)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predictions[\"classes\"])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "We create a classifer(say mnist_classifier) from the using the above function defined. We use this classifier to train our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_model_dir': './Model', '_save_checkpoints_secs': 600, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "                model_fn=digit_classifier, model_dir=\"./Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the above created classifier to train the model. Training is done in a batch size of 100 instead of taking the entire training data in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": train_data},\n",
    "            y=train_labels,\n",
    "            batch_size=100,\n",
    "            num_epochs=None,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function just prepares the training function and not the actual training. The actual tranining is done by feeding in this training function to the classifier. We don't run this function in our notebook as it's a long runinng function (around 5 hours). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier.train(\n",
    "            input_fn=train_input_fn,\n",
    "            steps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "Once the training is complete, I evaluate the model on *eval_data* data set to calculate the accuracy of this model. Since we have not run the training model above in the notebook, we will not be running the evaluation function as well. All these are locally run in the maching using both CPU + GPU to come up with the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": eval_data},\n",
    "                y=eval_labels,\n",
    "                num_epochs=1,\n",
    "                shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2017-09-23-07:13:55\n",
    "\n",
    "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-60004\n",
    "\n",
    "INFO:tensorflow:Finished evaluation at 2017-09-23-07:14:25\n",
    "\n",
    "INFO:tensorflow:Saving dict for global step 60004: accuracy = 0.9841, global_step = 60004, loss = 0.050626\n",
    "\n",
    "We observe an accuracy of 98.41% on the evaluation data of 10000 images. This says, that the model was able to rightly predict 9841 images out of 10000 evaluation images given in the MNIST data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
